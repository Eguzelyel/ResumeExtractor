{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "This is a sample text. The very first one.I will use this one for test.Keywords will include Machine Learning, Data Science, Tensorflow, NMT\n"
     ]
    }
   ],
   "source": [
    "# importing required modules \n",
    "import PyPDF2 \n",
    "\n",
    "# creating a pdf file object \n",
    "pdfFileObj = open('/Users/ekremguzelyel/Desktop/Assignments/Cs/Hackathons/ResumeExtractor/SamplePDF/1.pdf', 'rb') \n",
    "\n",
    "# creating a pdf reader object \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "\n",
    "# printing number of pages in pdf file \n",
    "print(pdfReader.numPages) \n",
    "\n",
    "# creating a page object \n",
    "pageObj = pdfReader.getPage(0) \n",
    "\n",
    "# extracting text from page \n",
    "print(pageObj.extractText()) \n",
    "\n",
    "# closing the pdf file object \n",
    "pdfFileObj.close() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sample text.\n",
      "\n",
      "The very first one.\n",
      "\n",
      "I will use this one for test.\n",
      "\n",
      "Keywords will include Machine Learning, Data Science, Tensorflow, NMT\n"
     ]
    }
   ],
   "source": [
    "f= open('/Users/ekremguzelyel/Desktop/Assignments/Cs/Hackathons/ResumeExtractor/SampleText/1.txt', 'r') \n",
    "print(f.read() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "!Ekrem Guzelyel\n",
      " B.S. & M.S in Computer Science, 2020     ekremguzelyel@gmail.com\n",
      " linkedin.com/in/ekrem\n",
      "-guzelyel\n",
      "  224 830 1998\n",
      " Chicago, IL 60642\n",
      " EDUCATION\n",
      " ILLINOIS INSTITUTE OF\n",
      " TECHNOLOGY\n",
      ", Chicago            \n",
      "                                               Expected\n",
      ", Dec\n",
      "ember\n",
      " 2020 Co-terminal Degree\n",
      " in Computer Science\n",
      " (B.S. & M.S.\n",
      " Joint Degree\n",
      ")  Specialization in Computational \n",
      "Intelligence\n",
      " Minor in Applied Mathematics\n",
      " Courses Taken\n",
      ": Elem. Linear Algebra, Discrete Structures, \n",
      "Data Structures & Algorithms, Data Mining, \n",
      "Probability/Statistics, Machine Learning\n",
      ", Deep Learning\n",
      ", Database Organizations\n",
      " GPA: 3.\n",
      "47/4.00\n",
      " WORK \n",
      "EXPERIENCE \n",
      " & PROJECTS\n",
      " Machine Learning Lab at IIT \n",
      "- Undergraduate Research Assistant, \n",
      "Chicago, IL\n",
      "                        October\n",
      " 2018-Present\n",
      " Research\n",
      ": ÒData Categorization for \n",
      "Transparent Text Classification\n",
      "Ó ¥!Summarize, preprocess movie reviews to desired format.\n",
      " ¥!Train a Convolutional Neural Network (CNN) model to classify text document\n",
      "s. ¥!Automate b\n",
      "ack propagat\n",
      "ion\n",
      " to identify\n",
      " reasoning for the decisions, using multiple models.\n",
      " Google\n",
      " - Engineering Practicum Intern (EP), \n",
      "Mountain View, \n",
      "CA   \n",
      "                                        May 2018\n",
      "-August 2018\n",
      " Project 1: \n",
      "ÒImproving Targeting Quality using TensorFlow ModelÓ\n",
      " ¥!Implemented a \n",
      "negative filtering \n",
      "for Google Search Ads using \n",
      "Deep Neural Networks\n",
      ". ¥!Created automated experiments to t\n",
      "une TensorFlow\n",
      " model performance.\n",
      " ¥!Observed significant improvements of quality (7.2%) over traditional logistic regression model.\n",
      " Project 2: \n",
      "ÒModel Age MonitorÓ\n",
      " ¥!Created, tested and launched an online monitoring system that successfully catches old models and \n",
      "executes \n",
      "on-call alert using Python.\n",
      "  ARC\n",
      " - Supplemental Instructor (SI)\n",
      "                                                                                August 2017\n",
      "-November 2017\n",
      " Held weekly tutoring and review sessions for Calculus I\n",
      " RESEARCH \n",
      "PROJECTS\n",
      " Chicago Pothole Problem: Pothole \n",
      "Filler Route\n",
      "                                                                        January 2019\n",
      "-Present\n",
      " Solve traveling salesman problem for the most efficient way to fill potholes looking at historical data.\n",
      "  Predicting Disease Span using Telomere Lengths \n",
      "- Sparta\n",
      "Hack V                         \n",
      "                                January 2019\n",
      " Cleaned and preprocessed N\n",
      "IH survey da\n",
      "ta and\n",
      " trained a DNN to predict telomere lengths.\n",
      " Locating Weaponry through Security Cameras \n",
      "- IIT: VLSI Lab\n",
      "                               September 2017\n",
      "-November 2017\n",
      " Collected and labeled video and photo data using LabelImg, vatic and ImageNet\n",
      " Analyzing the Effects of Public Housing (TOKI) to Elections \n",
      "- Rice University\n",
      "           August 2015\n",
      " - September 2015 \n",
      " Organized and analyzed data for\n",
      " gender and geographical distribution of votes using Java\n",
      " SKILLS\n",
      " Technical:\n",
      " Python\n",
      " (numpy, pandas\n",
      ", sklearn\n",
      "), TensorFlow\n",
      ", Keras\n",
      ", Jupyter\n",
      " Notebook, Java\n",
      ", Oracle, SQL\n",
      " Languages: English (Fluent), Turkish (Fluent), Spanish (Starter)\n",
      " AWARDS AND \n",
      "HONORS\n",
      "  DeanÕs\n",
      " List (Electrical Engineering Departme\n",
      "nt \n",
      "- IIT)            \n",
      "                                                  Fall 2016, Spring 2017\n",
      " National University Entrance Exam 1\n",
      "st & 2\n",
      "nd Stage (YGS\n",
      "-LYS\n",
      ")                                                        March, June 2014\n",
      " Ranked in top 25 among 2.086.087 students\n",
      " Physics Olympiad Student               \n",
      "                                                                                                          2010-2012 EXTRA\n",
      " CURRICULAR \n",
      "ACTIVITIES\n",
      "  ML@IIT (Machine Learning Club at IIT) \n",
      "- Events Chair                                                    \n",
      "     November 2018\n",
      "-Present\n",
      " Weekend School Teacher and Mentor at TASC            \n",
      "                                                      September \n",
      "2016-Present\n",
      " Teach Turkish Classes (Volunteer) for 1\n",
      "-5th grades\n",
      " Organize and lead Summer and Winter camps for high schoolers\n",
      " University\n",
      " Prep\n",
      " Presentations and \n",
      "How to Be Successful\n",
      " Seminars            \n",
      "                                             March 2015\n",
      "  16 Seminars Given in Istanbul, Kocaeli, Sakarya / TURKEY\n",
      " Recent Hackathons Attended: \n",
      "BoilerMake\n",
      ", LyftHack (2\n",
      "nd place )\n",
      ", SpartaHack\n",
      " V \n"
     ]
    }
   ],
   "source": [
    "# Another test with real resume.\n",
    "# creating a pdf file object \n",
    "pdfFileObj = open('/Users/ekremguzelyel/Desktop/Assignments/Cs/Hackathons/ResumeExtractor/SamplePDF/Sample_Resume.pdf', 'rb') \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "\n",
    "print(pdfReader.numPages) \n",
    "\n",
    "pageObj = pdfReader.getPage(0) \n",
    "text = pageObj.extractText()\n",
    "print(text)\n",
    "\n",
    "pdfFileObj.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!ekrem guzelyel b.s. & m.s in computer science, 2020 ekremguzelyel@gmail.com linkedin.com/in/ekrem -guzelyel 224 830 1998 chicago, il 60642 education illinois institute of technology , chicago expected , dec ember 2020 co-terminal degree in computer science (b.s. & m.s. joint degree ) specialization in computational intelligence minor in applied mathematics courses taken : elem. linear algebra, discrete structures, data structures & algorithms, data mining, probability/statistics, machine learning , deep learning , database organizations gpa: 3. 47/4.00 work experience & projects machine learning lab at iit - undergraduate research assistant, chicago, il october 2018-present research : òdata categorization for transparent text classification ó summarize, preprocess movie reviews to desired format. train a convolutional neural network (cnn) model to classify text document s. automate b ack propagat ion to identify reasoning for the decisions, using multiple models. google - engineering practicum intern (ep), mountain view, ca may 2018 -august 2018 project 1: òimproving targeting quality using tensorflow modeló implemented a negative filtering for google search ads using deep neural networks . created automated experiments to t une tensorflow model performance. observed significant improvements of quality (7.2%) over traditional logistic regression model. project 2: òmodel age monitoró created, tested and launched an online monitoring system that successfully catches old models and executes on-call alert using python. arc - supplemental instructor (si) august 2017 -november 2017 held weekly tutoring and review sessions for calculus i research projects chicago pothole problem: pothole filler route january 2019 -present solve traveling salesman problem for the most efficient way to fill potholes looking at historical data. predicting disease span using telomere lengths - sparta hack v january 2019 cleaned and preprocessed n ih survey da ta and trained a dnn to predict telomere lengths. locating weaponry through security cameras - iit: vlsi lab september 2017 -november 2017 collected and labeled video and photo data using labelimg, vatic and imagenet analyzing the effects of public housing (toki) to elections - rice university august 2015 - september 2015 organized and analyzed data for gender and geographical distribution of votes using java skills technical: python (numpy, pandas , sklearn ), tensorflow , keras , jupyter notebook, java , oracle, sql languages: english (fluent), turkish (fluent), spanish (starter) awards and honors deanõs list (electrical engineering departme nt - iit) fall 2016, spring 2017 national university entrance exam 1 st & 2 nd stage (ygs -lys ) march, june 2014 ranked in top 25 among 2.086.087 students physics olympiad student 2010-2012 extra curricular activities ml@iit (machine learning club at iit) - events chair november 2018 -present weekend school teacher and mentor at tasc september 2016-present teach turkish classes (volunteer) for 1 -5th grades organize and lead summer and winter camps for high schoolers university prep presentations and how to be successful seminars march 2015 16 seminars given in istanbul, kocaeli, sakarya / turkey recent hackathons attended: boilermake , lyfthack (2 nd place ) , spartahack v '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instead of the code next cell, this replaces all multiple spaces at once.\n",
    "text = re.sub(\"\\s\\s+\", \" \", text).lower()\n",
    "\n",
    "# Handle special characters.\n",
    "text = text.replace(\"Ó\",\"\\\"\").replace(\"Ò\",\"\\\"\").replace(\"¥!\", \"\").replace(\"Õ\",\"\\'\").replace(\"\\n\",\" \")\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "clean_text = clean_text.replace(\"  \", \" \").replace(\"Ó\",\"\\\"\").replace(\"Ò\",\"\\\"\").replace(\"¥!\", \"\").replace(\"Õ\",\"\\'\").replace(\"\\n\",\" \")\n",
    "# clean_text = clean_text.replace(\"Ó\",\"\\\"\")\n",
    "print(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are trials"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import re\n",
    "# re.findall(clean_text)\n",
    "r1 = re.findall(r\"\\s+\", clean_text)\n",
    "r2 = re.findall(r\"\\W+\", text)\n",
    "\n",
    "# reg_list = (re.split(r'(\\W+)|(\\w+(\\.+|@)\\w+)',clean_text))[1:-1] # The first and last elements are '' None.\n",
    "\n",
    "# reg_list = (re.split(r'(\\W+)',clean_text))[1:-1]\n",
    "reg_list = (re.split(r'[^(\\w+(\\.+|@)\\w+)]|[()]',clean_text))[1:-1]\n",
    "# [^((\\w+(\\.+|@)\\w+))]\n",
    "# # print(\" \".join(reg_list))\n",
    "key_list = list(filter(None,reg_list))\n",
    "# clean_text\n",
    "# print((re.split(r's','split the words')))\n",
    "# r2.string\n",
    "# clean_text.rfind(\"Machine Learning\")\n",
    "\" \".join(key_list)\n",
    "# list(filter(None,reg_list))\n",
    "key_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ekremguzelyel@gmail.com\n",
      "ml@iit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ekremguzelyel@gmail.com', 'ml@iit']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find emails\n",
    "abc = 'guru99@google.com, careerguru99@hotmail.com, users@yahoomail.com, Something @ Google.com'\n",
    "# This regex takes care of cases like \"I like to swim @ the ocean.\"\n",
    "emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "for email in emails:\n",
    "    print(email)\n",
    "    \n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOW THE REAL STUFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open PDF and clean the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of pages: 1\n",
      "ekrem guzelyel b.s. m.s in computer science 2020 ekremguzelyel@gmail.com linkedin.com in ekrem guzelyel 224 830 1998 chicago il 60642 education illinois institute of technology chicago expected dec ember 2020 co terminal degree in computer science b.s. m.s. joint degree specialization in computational intelligence minor in applied mathematics courses taken elem. linear algebra discrete structures data structures algorithms data mining probability statistics machine learning deep learning database organizations gpa 3. 47 4.00 work experience projects machine learning lab at iit undergraduate research assistant chicago il october 2018 present research data categorization for transparent text classification summarize preprocess movie reviews to desired format. train a convolutional neural network cnn model to classify text document s. automate b ack propagat ion to identify reasoning for the decisions using multiple models. google engineering practicum intern ep mountain view ca may 2018 august 2018 project 1 improving targeting quality using tensorflow model implemented a negative filtering for google search ads using deep neural networks . created automated experiments to t une tensorflow model performance. observed significant improvements of quality 7.2 over traditional logistic regression model. project 2 model age monitor created tested and launched an online monitoring system that successfully catches old models and executes on call alert using python. arc supplemental instructor si august 2017 november 2017 held weekly tutoring and review sessions for calculus i research projects chicago pothole problem pothole filler route january 2019 present solve traveling salesman problem for the most efficient way to fill potholes looking at historical data. predicting disease span using telomere lengths sparta hack v january 2019 cleaned and preprocessed n ih survey da ta and trained a dnn to predict telomere lengths. locating weaponry through security cameras iit vlsi lab september 2017 november 2017 collected and labeled video and photo data using labelimg vatic and imagenet analyzing the effects of public housing toki to elections rice university august 2015 september 2015 organized and analyzed data for gender and geographical distribution of votes using java skills technical python numpy pandas sklearn tensorflow keras jupyter notebook java oracle sql languages english fluent turkish fluent spanish starter awards and honors dean s list electrical engineering departme nt iit fall 2016 spring 2017 national university entrance exam 1 st 2 nd stage ygs lys march june 2014 ranked in top 25 among 2.086.087 students physics olympiad student 2010 2012 extra curricular activities ml@iit machine learning club at iit events chair november 2018 present weekend school teacher and mentor at tasc september 2016 present teach turkish classes volunteer for 1 5th grades organize and lead summer and winter camps for high schoolers university prep presentations and how to be successful seminars march 2015 16 seminars given in istanbul kocaeli sakarya turkey recent hackathons attended boilermake lyfthack 2 nd place spartahack v\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import PyPDF2 \n",
    "\n",
    "# Opening PDF file and cleaning text.\n",
    "\n",
    "pdfFileObj = open('/Users/ekremguzelyel/Desktop/Assignments/Cs/Hackathons/ResumeExtractor/SamplePDF/Sample_Resume.pdf', 'rb') \n",
    "pdfReader = PyPDF2.PdfFileReader(pdfFileObj) \n",
    "\n",
    "print(\"# of pages:\", pdfReader.numPages) \n",
    " \n",
    "pageObj = pdfReader.getPage(0) \n",
    "text = pageObj.extractText()\n",
    "pdfFileObj.close() \n",
    "\n",
    "# Clean spaces and handle special characters.\n",
    "text = re.sub(\"\\s\\s+\", \" \", text).lower()\n",
    "text = text.replace(\"ó\",\"\\\"\").replace(\"ò\",\"\\\"\").replace(\"¥!\", \"\").replace(\"õ\",\"'\").replace(\"\\n\",\" \")\n",
    "\n",
    "# Apply regex to get list of words.\n",
    "reg_list = (re.split(r'[^(\\w+(\\.+|@)\\w+)]|[()]', text))\n",
    "\n",
    "# Filter None values. -> Regex could be implemented better to eliminate this step. \n",
    "# but, it works. So don't touch it :D\n",
    "key_list = list(filter(None,reg_list))\n",
    "final_text = \" \".join(key_list)\n",
    "\n",
    "# print(text)\n",
    "print(final_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ekremguzelyel@gmail.com\n",
      "ml@iit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['ekremguzelyel@gmail.com', 'ml@iit']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find emails\n",
    "emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
    "for email in emails:\n",
    "    print(email)    \n",
    "emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
